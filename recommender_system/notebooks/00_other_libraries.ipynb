{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2480 entries, 0 to 2479\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   supplier_id  2480 non-null   int64  \n",
      " 1   subjects     2480 non-null   object \n",
      " 2   score        2480 non-null   float64\n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 58.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('sub_supplier_ratings.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. SURPRISE Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise import SVD, SVDpp, NormalPredictor, KNNBasic, BaselineOnly, CoClustering\n",
    "from surprise import SlopeOne, KNNBaseline, KNNWithMeans, KNNWithZScore\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "reader = Reader(rating_scale=(0, 1))\n",
    "\n",
    "data = Dataset.load_from_df(df[['supplier_id', 'subjects', 'score']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n"
     ]
    }
   ],
   "source": [
    "benchmark = []\n",
    "# Iterate over all algorithms\n",
    "for algorithm in [SVD(), SVDpp(), SlopeOne(), NormalPredictor(), KNNBaseline(), KNNBasic(), KNNWithMeans(), KNNWithZScore(), BaselineOnly(), CoClustering()]:\n",
    "    # Perform cross validation\n",
    "    results = cross_validate(algorithm, data, measures=['RMSE'], cv=3, verbose=False)\n",
    "    \n",
    "    # Get results & append algorithm name\n",
    "    tmp = pd.DataFrame.from_dict(results).mean(axis=0)\n",
    "    tmp = tmp.append(pd.Series([str(algorithm).split(' ')[0].split('.')[-1]], index=['Algorithm']))\n",
    "    benchmark.append(tmp)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>test_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KNNBaseline</th>\n",
       "      <td>0.137136</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.042908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNWithZScore</th>\n",
       "      <td>0.137319</td>\n",
       "      <td>0.004309</td>\n",
       "      <td>0.034171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaselineOnly</th>\n",
       "      <td>0.138157</td>\n",
       "      <td>0.001233</td>\n",
       "      <td>0.001638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNWithMeans</th>\n",
       "      <td>0.139151</td>\n",
       "      <td>0.002666</td>\n",
       "      <td>0.030563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SlopeOne</th>\n",
       "      <td>0.141420</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.008429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVDpp</th>\n",
       "      <td>0.141491</td>\n",
       "      <td>0.438943</td>\n",
       "      <td>0.018212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNBasic</th>\n",
       "      <td>0.147297</td>\n",
       "      <td>0.002355</td>\n",
       "      <td>0.026962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVD</th>\n",
       "      <td>0.154877</td>\n",
       "      <td>0.061298</td>\n",
       "      <td>0.004401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CoClustering</th>\n",
       "      <td>0.158023</td>\n",
       "      <td>0.018635</td>\n",
       "      <td>0.002000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NormalPredictor</th>\n",
       "      <td>0.188043</td>\n",
       "      <td>0.001040</td>\n",
       "      <td>0.002871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 test_rmse  fit_time  test_time\n",
       "Algorithm                                      \n",
       "KNNBaseline       0.137136  0.003000   0.042908\n",
       "KNNWithZScore     0.137319  0.004309   0.034171\n",
       "BaselineOnly      0.138157  0.001233   0.001638\n",
       "KNNWithMeans      0.139151  0.002666   0.030563\n",
       "SlopeOne          0.141420  0.001000   0.008429\n",
       "SVDpp             0.141491  0.438943   0.018212\n",
       "KNNBasic          0.147297  0.002355   0.026962\n",
       "SVD               0.154877  0.061298   0.004401\n",
       "CoClustering      0.158023  0.018635   0.002000\n",
       "NormalPredictor   0.188043  0.001040   0.002871"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(benchmark).set_index('Algorithm').sort_values('test_rmse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Light FM Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import precision_at_k\n",
    "from lightfm.evaluation import auc_score\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'supplier_features.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\Sample_data\\01_Recommender_Systems\\00_other_libraries.ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Sample_data/01_Recommender_Systems/00_other_libraries.ipynb#ch0000008?line=0'>1</a>\u001b[0m adj_matrix \u001b[39m=\u001b[39m sparse\u001b[39m.\u001b[39mcsr_matrix(pd\u001b[39m.\u001b[39mpivot(df, index\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39msupplier_id\u001b[39m\u001b[39m'\u001b[39m], columns\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msubjects\u001b[39m\u001b[39m'\u001b[39m, values\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mscore\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mvalues)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Sample_data/01_Recommender_Systems/00_other_libraries.ipynb#ch0000008?line=1'>2</a>\u001b[0m supplier_features \u001b[39m=\u001b[39m sparse\u001b[39m.\u001b[39mcsr_matrix(pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39msupplier_features.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39mvalues)\n",
      "File \u001b[1;32mc:\\Users\\vijay.rameshkumar\\Anaconda3\\envs\\myenv\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/vijay.rameshkumar/Anaconda3/envs/myenv/lib/site-packages/pandas/util/_decorators.py?line=304'>305</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    <a href='file:///c%3A/Users/vijay.rameshkumar/Anaconda3/envs/myenv/lib/site-packages/pandas/util/_decorators.py?line=305'>306</a>\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    <a href='file:///c%3A/Users/vijay.rameshkumar/Anaconda3/envs/myenv/lib/site-packages/pandas/util/_decorators.py?line=306'>307</a>\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[0;32m    <a href='file:///c%3A/Users/vijay.rameshkumar/Anaconda3/envs/myenv/lib/site-packages/pandas/util/_decorators.py?line=307'>308</a>\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    <a href='file:///c%3A/Users/vijay.rameshkumar/Anaconda3/envs/myenv/lib/site-packages/pandas/util/_decorators.py?line=308'>309</a>\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[0;32m    <a href='file:///c%3A/Users/vijay.rameshkumar/Anaconda3/envs/myenv/lib/site-packages/pandas/util/_decorators.py?line=309'>310</a>\u001b[0m     )\n\u001b[1;32m--> <a href='file:///c%3A/Users/vijay.rameshkumar/Anaconda3/envs/myenv/lib/site-packages/pandas/util/_decorators.py?line=310'>311</a>\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\vijay.rameshkumar\\Anaconda3\\envs\\myenv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/vijay.rameshkumar/Anaconda3/envs/myenv/lib/site-packages/pandas/io/parsers/readers.py?line=664'>665</a>\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    <a href='file:///c%3A/Users/vijay.rameshkumar/Anaconda3/envs/myenv/lib/site-packages/pandas/io/parsers/readers.py?line=665'>666</a>\u001b[0m     dialect,\n\u001b[0;32m    <a href='file:///c%3A/Users/vijay.rameshkumar/Anaconda3/envs/myenv/lib/site-packages/pandas/io/parsers/readers.py?line=666'>667</a>\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/vijay.rameshkumar/Anaconda3/envs/myenv/lib/site-packages/pandas/io/parsers/readers.py?line=675'>676</a>\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    <a href='file:///c%3A/Users/vijay.rameshkumar/Anaconda3/envs/myenv/lib/site-packages/pandas/io/parsers/readers.py?line=676'>677</a>\u001b[0m )\n\u001b[0;32m    <a href='file:///c%3A/Users/vijay.rameshkumar/Anaconda3/envs/myenv/lib/site-packages/pandas/io/parsers/readers.py?line=677'>678</a>\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> <a href='file:///c%3A/Users/vijay.rameshkumar/Anaconda3/envs/myenv/lib/site-packages/pandas/io/parsers/readers.py?line=679'>680</a>\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\vijay.rameshkumar\\Anaconda3\\envs\\myenv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/vijay.rameshkumar/Anaconda3/envs/myenv/lib/site-packages/pandas/io/parsers/readers.py?line=571'>572</a>\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    <a href='file:///c%3A/Users/vijay.rameshkumar/Anaconda3/envs/myenv/lib/site-packages/pandas/io/parsers/readers.py?line=573'>574</a>\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/vijay.rameshkumar/Anaconda3/envs/myenv/lib/site-packages/pandas/io/parsers/readers.py?line=574'>575</a>\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    <a href='file:///c%3A/Users/vijay.rameshkumar/Anaconda3/envs/myenv/lib/site-packages/pandas/io/parsers/readers.py?line=576'>577</a>\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    <a href='file:///c%3A/Users/vijay.rameshkumar/Anaconda3/envs/myenv/lib/site-packages/pandas/io/parsers/readers.py?line=577'>578</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\vijay.rameshkumar\\Anaconda3\\envs\\myenv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/vijay.rameshkumar/Anaconda3/envs/myenv/lib/site-packages/pandas/io/parsers/readers.py?line=929'>930</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    <a href='file:///c%3A/Users/vijay.rameshkumar/Anaconda3/envs/myenv/lib/site-packages/pandas/io/parsers/readers.py?line=931'>932</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/vijay.rameshkumar/Anaconda3/envs/myenv/lib/site-packages/pandas/io/parsers/readers.py?line=932'>933</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32mc:\\Users\\vijay.rameshkumar\\Anaconda3\\envs\\myenv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/vijay.rameshkumar/Anaconda3/envs/myenv/lib/site-packages/pandas/io/parsers/readers.py?line=1212'>1213</a>\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   <a href='file:///c%3A/Users/vijay.rameshkumar/Anaconda3/envs/myenv/lib/site-packages/pandas/io/parsers/readers.py?line=1213'>1214</a>\u001b[0m \u001b[39m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/vijay.rameshkumar/Anaconda3/envs/myenv/lib/site-packages/pandas/io/parsers/readers.py?line=1214'>1215</a>\u001b[0m \u001b[39m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/vijay.rameshkumar/Anaconda3/envs/myenv/lib/site-packages/pandas/io/parsers/readers.py?line=1215'>1216</a>\u001b[0m \u001b[39m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/Users/vijay.rameshkumar/Anaconda3/envs/myenv/lib/site-packages/pandas/io/parsers/readers.py?line=1216'>1217</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(  \u001b[39m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/vijay.rameshkumar/Anaconda3/envs/myenv/lib/site-packages/pandas/io/parsers/readers.py?line=1217'>1218</a>\u001b[0m     f,\n\u001b[0;32m   <a href='file:///c%3A/Users/vijay.rameshkumar/Anaconda3/envs/myenv/lib/site-packages/pandas/io/parsers/readers.py?line=1218'>1219</a>\u001b[0m     mode,\n\u001b[0;32m   <a href='file:///c%3A/Users/vijay.rameshkumar/Anaconda3/envs/myenv/lib/site-packages/pandas/io/parsers/readers.py?line=1219'>1220</a>\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   <a href='file:///c%3A/Users/vijay.rameshkumar/Anaconda3/envs/myenv/lib/site-packages/pandas/io/parsers/readers.py?line=1220'>1221</a>\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   <a href='file:///c%3A/Users/vijay.rameshkumar/Anaconda3/envs/myenv/lib/site-packages/pandas/io/parsers/readers.py?line=1221'>1222</a>\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   <a href='file:///c%3A/Users/vijay.rameshkumar/Anaconda3/envs/myenv/lib/site-packages/pandas/io/parsers/readers.py?line=1222'>1223</a>\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   <a href='file:///c%3A/Users/vijay.rameshkumar/Anaconda3/envs/myenv/lib/site-packages/pandas/io/parsers/readers.py?line=1223'>1224</a>\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   <a href='file:///c%3A/Users/vijay.rameshkumar/Anaconda3/envs/myenv/lib/site-packages/pandas/io/parsers/readers.py?line=1224'>1225</a>\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   <a href='file:///c%3A/Users/vijay.rameshkumar/Anaconda3/envs/myenv/lib/site-packages/pandas/io/parsers/readers.py?line=1225'>1226</a>\u001b[0m )\n\u001b[0;32m   <a href='file:///c%3A/Users/vijay.rameshkumar/Anaconda3/envs/myenv/lib/site-packages/pandas/io/parsers/readers.py?line=1226'>1227</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/vijay.rameshkumar/Anaconda3/envs/myenv/lib/site-packages/pandas/io/parsers/readers.py?line=1227'>1228</a>\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\vijay.rameshkumar\\Anaconda3\\envs\\myenv\\lib\\site-packages\\pandas\\io\\common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/vijay.rameshkumar/Anaconda3/envs/myenv/lib/site-packages/pandas/io/common.py?line=783'>784</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/Users/vijay.rameshkumar/Anaconda3/envs/myenv/lib/site-packages/pandas/io/common.py?line=784'>785</a>\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/vijay.rameshkumar/Anaconda3/envs/myenv/lib/site-packages/pandas/io/common.py?line=785'>786</a>\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/vijay.rameshkumar/Anaconda3/envs/myenv/lib/site-packages/pandas/io/common.py?line=786'>787</a>\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    <a href='file:///c%3A/Users/vijay.rameshkumar/Anaconda3/envs/myenv/lib/site-packages/pandas/io/common.py?line=787'>788</a>\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/vijay.rameshkumar/Anaconda3/envs/myenv/lib/site-packages/pandas/io/common.py?line=788'>789</a>\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    <a href='file:///c%3A/Users/vijay.rameshkumar/Anaconda3/envs/myenv/lib/site-packages/pandas/io/common.py?line=789'>790</a>\u001b[0m             handle,\n\u001b[0;32m    <a href='file:///c%3A/Users/vijay.rameshkumar/Anaconda3/envs/myenv/lib/site-packages/pandas/io/common.py?line=790'>791</a>\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    <a href='file:///c%3A/Users/vijay.rameshkumar/Anaconda3/envs/myenv/lib/site-packages/pandas/io/common.py?line=791'>792</a>\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    <a href='file:///c%3A/Users/vijay.rameshkumar/Anaconda3/envs/myenv/lib/site-packages/pandas/io/common.py?line=792'>793</a>\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    <a href='file:///c%3A/Users/vijay.rameshkumar/Anaconda3/envs/myenv/lib/site-packages/pandas/io/common.py?line=793'>794</a>\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    <a href='file:///c%3A/Users/vijay.rameshkumar/Anaconda3/envs/myenv/lib/site-packages/pandas/io/common.py?line=794'>795</a>\u001b[0m         )\n\u001b[0;32m    <a href='file:///c%3A/Users/vijay.rameshkumar/Anaconda3/envs/myenv/lib/site-packages/pandas/io/common.py?line=795'>796</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/vijay.rameshkumar/Anaconda3/envs/myenv/lib/site-packages/pandas/io/common.py?line=796'>797</a>\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/vijay.rameshkumar/Anaconda3/envs/myenv/lib/site-packages/pandas/io/common.py?line=797'>798</a>\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'supplier_features.csv'"
     ]
    }
   ],
   "source": [
    "adj_matrix = sparse.csr_matrix(pd.pivot(df, index=['supplier_id'], columns='subjects', values='score').values)\n",
    "supplier_features = sparse.csr_matrix(pd.read_csv('supplier_features.csv').values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_samples = pd.read_csv('positive_known_ratings.csv')\n",
    "positive_samples['suppliers__ref'] = positive_samples['suppliers__ref'].astype('int32')\n",
    "test = pd.pivot(positive_samples, index=['suppliers__ref'], columns='projects__study_types_subject_ids', values='positive_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 417 entries, 0 to 416\n",
      "Data columns (total 2 columns):\n",
      " #   Column                             Non-Null Count  Dtype \n",
      "---  ------                             --------------  ----- \n",
      " 0   suppliers__ref                     417 non-null    int32 \n",
      " 1   projects__study_types_subject_ids  417 non-null    object\n",
      "dtypes: int32(1), object(1)\n",
      "memory usage: 5.0+ KB\n"
     ]
    }
   ],
   "source": [
    "positive_samples[['suppliers__ref', 'projects__study_types_subject_ids']].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x24d9cba80a0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = LightFM(loss='warp',\n",
    "                random_state=2016,\n",
    "                learning_rate=0.01,\n",
    "                no_components=3)\n",
    "model1.fit(supplier_features, epochs=10)\n",
    "\n",
    "# preds = []\n",
    "# for i in positive_samples[['suppliers__ref', 'projects__study_types_subject_ids']].itertuples():\n",
    "#     preds.append(model1.predict(int(i[1]), i[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Tensorflow Recommenders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_samples['suppliers__ref'] = positive_samples['suppliers__ref'].astype('str')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. List Wise Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import tensorflow_ranking as tfr\n",
    "import tensorflow_recommenders as tfrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['suppliers__ref', 'projects__study_types_subject_ids']\n",
    "target = []\n",
    "\n",
    "training_dataset = (\n",
    "    tf.data.Dataset.from_tensor_slices(\n",
    "        (\n",
    "            tf.cast(positive_samples['suppliers__ref'].values, tf.string),\n",
    "            tf.cast(positive_samples['projects__study_types_subject_ids'].values, tf.string),\n",
    "            tf.cast(positive_samples['positive_score'].values, tf.float32)\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "ratings = training_dataset.map(lambda x,y,z: {\n",
    "    \"movie_title\": y,\n",
    "    \"user_id\": x,\n",
    "    \"user_rating\": z,\n",
    "})\n",
    "movies = ratings.map(lambda x:x['movie_title'])\n",
    "\n",
    "unique_movie_titles = positive_samples['projects__study_types_subject_ids'].unique()\n",
    "unique_user_ids = positive_samples['suppliers__ref'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "# Split between train and tests sets, as before.\n",
    "shuffled = ratings.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled.take(80_000)\n",
    "test = shuffled.skip(80_000).take(20_000)\n",
    "\n",
    "# We sample 50 lists for each user for the training data. For each list we\n",
    "# sample 5 movies from the movies the user rated.\n",
    "train = tfrs.examples.movielens.sample_listwise(\n",
    "    train,\n",
    "    num_list_per_user=50,\n",
    "    num_examples_per_list=5,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "test = tfrs.examples.movielens.sample_listwise(\n",
    "    test,\n",
    "    num_list_per_user=1,\n",
    "    num_examples_per_list=5,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'movie_title': <tf.Tensor: shape=(5,), dtype=string, numpy=\n",
      "array([b'other', b'grooming_cosmetics', b'marketing_advertising',\n",
      "       b'finance_legal_insurance', b'entertainment'], dtype=object)>,\n",
      " 'user_id': <tf.Tensor: shape=(), dtype=string, numpy=b'458'>,\n",
      " 'user_rating': <tf.Tensor: shape=(5,), dtype=float32, numpy=array([0.04, 0.  , 0.02, 0.32, 0.  ], dtype=float32)>}\n"
     ]
    }
   ],
   "source": [
    "for example in train.take(1):\n",
    "  pprint.pprint(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RankingModel(tfrs.Model):\n",
    "\n",
    "  def __init__(self, loss):\n",
    "    super().__init__()\n",
    "    embedding_dimension = 32\n",
    "\n",
    "    # Compute embeddings for users.\n",
    "    self.user_embeddings = tf.keras.Sequential([\n",
    "      tf.keras.layers.StringLookup(\n",
    "        vocabulary=tf.convert_to_tensor(unique_user_ids)),\n",
    "      tf.keras.layers.Embedding(len(unique_user_ids) + 2, embedding_dimension)\n",
    "    ])\n",
    "\n",
    "    # Compute embeddings for movies.\n",
    "    self.movie_embeddings = tf.keras.Sequential([\n",
    "      tf.keras.layers.StringLookup(\n",
    "        vocabulary=tf.convert_to_tensor(unique_movie_titles)),\n",
    "      tf.keras.layers.Embedding(len(unique_movie_titles) + 2, embedding_dimension)\n",
    "    ])\n",
    "\n",
    "    # Compute predictions.\n",
    "    self.score_model = tf.keras.Sequential([\n",
    "      # Learn multiple dense layers.\n",
    "      tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "      tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "      # Make rating predictions in the final layer.\n",
    "      tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "    self.task = tfrs.tasks.Ranking(\n",
    "      loss=loss,\n",
    "      metrics=[\n",
    "        tfr.keras.metrics.NDCGMetric(name=\"ndcg_metric\"),\n",
    "        tf.keras.metrics.RootMeanSquaredError()\n",
    "      ]\n",
    "    )\n",
    "\n",
    "  def call(self, features):\n",
    "    # We first convert the id features into embeddings.\n",
    "    # User embeddings are a [batch_size, embedding_dim] tensor.\n",
    "    user_embeddings = self.user_embeddings(features[\"user_id\"])\n",
    "\n",
    "    # Movie embeddings are a [batch_size, num_movies_in_list, embedding_dim]\n",
    "    # tensor.\n",
    "    movie_embeddings = self.movie_embeddings(features[\"movie_title\"])\n",
    "\n",
    "    # We want to concatenate user embeddings with movie emebeddings to pass\n",
    "    # them into the ranking model. To do so, we need to reshape the user\n",
    "    # embeddings to match the shape of movie embeddings.\n",
    "    list_length = features[\"movie_title\"].shape[1]\n",
    "    user_embedding_repeated = tf.repeat(\n",
    "        tf.expand_dims(user_embeddings, 1), [list_length], axis=1)\n",
    "\n",
    "    # Once reshaped, we concatenate and pass into the dense layers to generate\n",
    "    # predictions.\n",
    "    concatenated_embeddings = tf.concat(\n",
    "        [user_embedding_repeated, movie_embeddings], 2)\n",
    "\n",
    "    return self.score_model(concatenated_embeddings)\n",
    "\n",
    "  def compute_loss(self, features, training=False):\n",
    "    labels = features.pop(\"user_rating\")\n",
    "\n",
    "    scores = self(features)\n",
    "\n",
    "    return self.task(\n",
    "        labels=labels,\n",
    "        predictions=tf.squeeze(scores, axis=-1),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "\n",
    "cached_train = train.shuffle(100_000).batch(2).cache()\n",
    "cached_test = test.batch(2).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean squared error model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_model = RankingModel(tf.keras.losses.MeanSquaredError())\n",
    "mse_model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "625/625 [==============================] - 6s 3ms/step - ndcg_metric: 0.9033 - root_mean_squared_error: 0.2046 - loss: 0.0418 - regularization_loss: 0.0000e+00 - total_loss: 0.0418\n",
      "Epoch 2/3\n",
      "625/625 [==============================] - 2s 3ms/step - ndcg_metric: 0.9726 - root_mean_squared_error: 0.0954 - loss: 0.0091 - regularization_loss: 0.0000e+00 - total_loss: 0.0091\n",
      "Epoch 3/3\n",
      "625/625 [==============================] - 2s 3ms/step - ndcg_metric: 0.9895 - root_mean_squared_error: 0.0481 - loss: 0.0023 - regularization_loss: 0.0000e+00 - total_loss: 0.0023\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29e9eb35c70>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_model.fit(cached_train, epochs=epochs, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pairwise hinge loss model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hinge_model = RankingModel(tfr.keras.losses.PairwiseHingeLoss())\n",
    "hinge_model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "625/625 [==============================] - 4s 3ms/step - ndcg_metric: 0.9217 - root_mean_squared_error: 1.6702 - loss: 0.9650 - regularization_loss: 0.0000e+00 - total_loss: 0.9650\n",
      "Epoch 2/3\n",
      "625/625 [==============================] - 2s 3ms/step - ndcg_metric: 0.9864 - root_mean_squared_error: 3.7178 - loss: 0.2994 - regularization_loss: 0.0000e+00 - total_loss: 0.2994\n",
      "Epoch 3/3\n",
      "625/625 [==============================] - 2s 3ms/step - ndcg_metric: 0.9940 - root_mean_squared_error: 5.0590 - loss: 0.1638 - regularization_loss: 0.0000e+00 - total_loss: 0.1638\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29ea22dc700>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hinge_model.fit(cached_train, epochs=epochs, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listwise model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listwise_model = RankingModel(tfr.keras.losses.ListMLELoss())\n",
    "listwise_model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "625/625 [==============================] - 4s 3ms/step - ndcg_metric: 0.9193 - root_mean_squared_error: 2.4997 - loss: 3.3447 - regularization_loss: 0.0000e+00 - total_loss: 3.3447\n",
      "Epoch 2/3\n",
      "625/625 [==============================] - 3s 4ms/step - ndcg_metric: 0.9860 - root_mean_squared_error: 5.5020 - loss: 1.6785 - regularization_loss: 0.0000e+00 - total_loss: 1.6785\n",
      "Epoch 3/3\n",
      "625/625 [==============================] - 2s 4ms/step - ndcg_metric: 0.9933 - root_mean_squared_error: 7.5963 - loss: 1.2140 - regularization_loss: 0.0000e+00 - total_loss: 1.2140\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29ea0211f10>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listwise_model.fit(cached_train, epochs=epochs, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Ranking based Recommenders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint\n",
    "import tempfile\n",
    "\n",
    "from typing import Dict, Text\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_recommenders as tfrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Preparing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['suppliers__ref', 'projects__study_types_subject_ids']\n",
    "target = []\n",
    "\n",
    "training_dataset = (\n",
    "    tf.data.Dataset.from_tensor_slices(\n",
    "        (\n",
    "            tf.cast(positive_samples['suppliers__ref'].values, tf.string),\n",
    "            tf.cast(positive_samples['projects__study_types_subject_ids'].values, tf.string),\n",
    "            tf.cast(positive_samples['positive_score'].values, tf.float32)\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "ratings = training_dataset.map(lambda x,y,z: {\n",
    "    \"subject_id\": y,\n",
    "    \"supplier_id\": x,\n",
    "    \"score\": z,\n",
    "})\n",
    "\n",
    "subjects = ratings.map(lambda x:x['subject_id'])\n",
    "\n",
    "unique_subjects = positive_samples['projects__study_types_subject_ids'].unique()\n",
    "unique_suppliers = positive_samples['suppliers__ref'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "shuffled = ratings.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled.take(80_000)\n",
    "test = shuffled.skip(80_000).take(20_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Implementing a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RankingModel(tf.keras.Model):\n",
    "\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    embedding_dimension = 32\n",
    "\n",
    "    # Compute embeddings for users.\n",
    "    self.supplier_embeddings = tf.keras.Sequential([\n",
    "      tf.keras.layers.StringLookup(\n",
    "        vocabulary=unique_suppliers, mask_token=None),\n",
    "      tf.keras.layers.Embedding(len(unique_suppliers) + 1, embedding_dimension)\n",
    "    ])\n",
    "\n",
    "    # Compute embeddings for movies.\n",
    "    self.subject_embeddings = tf.keras.Sequential([\n",
    "      tf.keras.layers.StringLookup(\n",
    "        vocabulary=unique_subjects, mask_token=None),\n",
    "      tf.keras.layers.Embedding(len(unique_subjects) + 1, embedding_dimension)\n",
    "    ])\n",
    "\n",
    "    # Compute predictions.\n",
    "    self.ratings = tf.keras.Sequential([\n",
    "      # Learn multiple dense layers.\n",
    "      tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "      tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "      # Make rating predictions in the final layer.\n",
    "      tf.keras.layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "  def call(self, inputs):\n",
    "\n",
    "    supplier_id, subject_id = inputs\n",
    "\n",
    "    supplier_embedding = self.supplier_embeddings(supplier_id)\n",
    "    subject_embedding = self.subject_embeddings(subject_id)\n",
    "\n",
    "    return self.ratings(tf.concat([supplier_embedding, subject_embedding], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupplierRecommender(tfrs.models.Model):\n",
    "\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.ranking_model: tf.keras.Model = RankingModel()\n",
    "    self.task: tf.keras.layers.Layer = tfrs.tasks.Ranking(\n",
    "      loss = tf.keras.losses.MeanSquaredError(),\n",
    "      metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
    "    )\n",
    "\n",
    "  def call(self, features: Dict[str, tf.Tensor]) -> tf.Tensor:\n",
    "    return self.ranking_model(\n",
    "        (features[\"supplier_id\"], features[\"subject_id\"]))\n",
    "\n",
    "  def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "    labels = features.pop(\"score\")\n",
    "\n",
    "    rating_predictions = self(features)\n",
    "\n",
    "    # The task computes the loss and the metrics.\n",
    "    return self.task(labels=labels, predictions=rating_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_train = train.shuffle(100_000).batch(10).cache()\n",
    "cached_test = test.batch(2).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "42/42 [==============================] - 1s 4ms/step - root_mean_squared_error: 0.2711 - loss: 0.0737 - regularization_loss: 0.0000e+00 - total_loss: 0.0737\n",
      "Epoch 2/4\n",
      "42/42 [==============================] - 0s 4ms/step - root_mean_squared_error: 0.2531 - loss: 0.0641 - regularization_loss: 0.0000e+00 - total_loss: 0.0641\n",
      "Epoch 3/4\n",
      "42/42 [==============================] - 0s 4ms/step - root_mean_squared_error: 0.2388 - loss: 0.0571 - regularization_loss: 0.0000e+00 - total_loss: 0.0571\n",
      "Epoch 4/4\n",
      "42/42 [==============================] - 0s 3ms/step - root_mean_squared_error: 0.2275 - loss: 0.0518 - regularization_loss: 0.0000e+00 - total_loss: 0.0518\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29ea6b87580>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SupplierRecommender()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))\n",
    "model.fit(cached_train, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<CacheDataset element_spec={'subject_id': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'supplier_id': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'score': TensorSpec(shape=(None,), dtype=tf.float32, name=None)}>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cached_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.evaluate(cached_test, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "\n",
    "for i in positive_samples.itertuples():\n",
    "    preds.append(model({\n",
    "        \"supplier_id\": np.array([i[1]]),\n",
    "        \"subject_id\": np.array([i[2]])\n",
    "        }).numpy().tolist()[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_samples['preds'] = pd.Series(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.186411052942276, 0.17048010230064392, 0.40434226393699646, 0.30209293961524963, 0.24737195670604706, 0.3803718090057373, 0.3860608637332916, 0.32912567257881165, 0.27031415700912476, 0.1074674054980278, 0.1137082576751709, 0.1268240064382553, 0.08942921459674835, 0.13704340159893036, 0.09185008704662323, 0.2037433534860611, 0.1362847536802292, 0.11112768948078156, 0.10015000402927399, 0.11726918071508408, 0.13068561255931854, 0.09657150506973267, 0.11846281588077545, 0.12199914455413818, 0.4581640660762787, 0.1459229737520218, 0.09529384970664978, 0.10233353823423386, 0.0840628445148468, 0.1456412374973297, 0.14586901664733887, 0.12258178740739822, 0.36383944749832153, 0.35718849301338196, 0.26017630100250244, 0.2239917665719986, 0.13559921085834503, 0.14297130703926086, 0.24791786074638367, 0.1892600953578949, 0.19448764622211456, 0.20673449337482452, 0.13167281448841095, 0.1906924843788147, 0.10848350077867508, 0.12293143570423126, 0.11321958154439926, 0.13423378765583038, 0.17748603224754333, 0.0928511694073677, 0.15290534496307373, 0.09920123219490051, 0.22913812100887299, 0.15497055649757385, 0.11825191229581833, 0.11297568678855896, 0.27658259868621826, 0.15599654614925385, 0.11563289165496826, 0.1535792201757431, 0.10451605916023254, 0.12144061177968979, 0.1246948316693306, 0.13378341495990753, 0.13443514704704285, 0.14021126925945282, 0.4652354419231415, 0.36697691679000854, 0.15889804065227509, 0.1017504632472992, 0.17795813083648682, 0.13611045479774475, 0.11281614005565643, 0.09045162051916122, 0.15989893674850464, 0.16931560635566711, 0.20993822813034058, 0.12045378983020782, 0.1376732438802719, 0.15602879226207733, 0.13133561611175537, 0.23916515707969666, 0.29302334785461426, 0.44612550735473633, 0.18800245225429535, 0.20652246475219727, 0.3194337785243988, 0.24028447270393372, 0.21587038040161133, 0.28665149211883545, 0.2085852473974228, 0.2625851333141327, 0.27682578563690186, 0.19772717356681824, 0.37486669421195984, 0.33969539403915405, 0.14165814220905304, 0.1888088881969452, 0.3056293725967407, 0.2776567339897156, 0.39411965012550354, 0.11842121928930283, 0.20410072803497314, 0.2946130335330963, 0.3112550973892212, 0.1681348979473114, 0.24591970443725586, 0.43355897068977356, 0.29837316274642944, 0.49024611711502075, 0.28062984347343445, 0.3297004699707031, 0.36268627643585205, 0.4491212069988251, 0.30408692359924316, 0.3574565649032593, 0.3145320415496826, 0.3972896337509155, 0.29779085516929626, 0.415658563375473, 0.48621615767478943, 0.4218972623348236, 0.37727001309394836, 0.35303646326065063, 0.3341728448867798, 0.3753048777580261, 0.3794593811035156, 0.41010740399360657, 0.695366621017456, 0.6198737621307373, 0.46381500363349915, 0.355251669883728, 0.18108108639717102, 0.20578992366790771, 0.2893843650817871, 0.26666557788848877, 0.3044685423374176, 0.17456406354904175, 0.26835107803344727, 0.227891206741333, 0.1733807474374771, 0.1492592990398407, 0.10822895169258118, 0.16093173623085022, 0.13209688663482666, 0.28323307633399963, 0.40598025918006897, 0.12023205310106277, 0.10753825306892395, 0.12783440947532654, 0.15335442125797272, 0.13676612079143524, 0.19635988771915436, 0.19172528386116028, 0.21038511395454407, 0.18870261311531067, 0.13075876235961914, 0.22353681921958923, 0.1537402868270874, 0.15275277197360992, 0.1314598023891449, 0.14631274342536926, 0.27279168367385864, 0.3530732989311218, 0.2420968860387802, 0.35786914825439453, 0.29907500743865967, 0.25291696190834045, 0.3403860032558441, 0.3159429132938385, 0.1401807963848114, 0.16796812415122986, 0.3413360118865967, 0.19419455528259277, 0.12136377394199371, 0.19088847935199738, 0.1426602602005005, 0.1398663967847824, 0.13231812417507172, 0.18074914813041687, 0.12769226729869843, 0.15988513827323914, 0.179592102766037, 0.22015687823295593, 0.12348060309886932, 0.2743898630142212, 0.3046824336051941, 0.2746659517288208, 0.2859349250793457, 0.10499335080385208, 0.15537330508232117, 0.22055304050445557, 0.13066838681697845, 0.1262800395488739, 0.14252901077270508, 0.13889344036579132, 0.2928209900856018, 0.41520294547080994, 0.17575132846832275, 0.24065625667572021, 0.16223369538784027, 0.14532940089702606, 0.26790112257003784, 0.14983947575092316, 0.14043240249156952, 0.14656966924667358, 0.1566976010799408, 0.22934313118457794, 0.1465378999710083, 0.3771619200706482, 0.33470118045806885, 0.36155062913894653, 0.16946327686309814, 0.2104414999485016, 0.3787393569946289, 0.13627475500106812, 0.22706690430641174, 0.13886432349681854, 0.31121984124183655, 0.21973629295825958, 0.17869612574577332, 0.17058764398097992, 0.16129040718078613, 0.21432611346244812, 0.1434502750635147, 0.19484743475914001, 0.5430603623390198, 0.4487612545490265, 0.24958288669586182, 0.1497621387243271, 0.2887954115867615, 0.22622375190258026, 0.17655758559703827, 0.2183416187763214, 0.26998403668403625, 0.28440797328948975, 0.28079602122306824, 0.23951445519924164, 0.21626462042331696, 0.18171963095664978, 0.22849395871162415, 0.32578983902931213, 0.30211254954338074, 0.11843707412481308, 0.12542766332626343, 0.1065177246928215, 0.13552409410476685, 0.19171735644340515, 0.09035898745059967, 0.14811085164546967, 0.10200338065624237, 0.2295120507478714, 0.16370460391044617, 0.13040152192115784, 0.12288124114274979, 0.2893042266368866, 0.15837861597537994, 0.13438960909843445, 0.1499272733926773, 0.11034674942493439, 0.13729843497276306, 0.13337558507919312, 0.1338171511888504, 0.14165420830249786, 0.1489441841840744, 0.47835057973861694, 0.38389527797698975, 0.18606680631637573, 0.1393522173166275, 0.11648821085691452, 0.09000957012176514, 0.1739504486322403, 0.21822980046272278, 0.12497822940349579, 0.16205735504627228, 0.129917174577713, 0.2373206615447998, 0.13219362497329712, 0.1724853664636612, 0.12898848950862885, 0.13933001458644867, 0.1318891942501068, 0.1940474957227707, 0.3230891227722168, 0.4043355882167816, 0.278661847114563, 0.237945556640625, 0.3034341335296631, 0.2889295220375061, 0.2873539626598358, 0.12565641105175018, 0.3443474769592285, 0.46111029386520386, 0.5149934887886047, 0.48023736476898193, 0.42942506074905396, 0.37878653407096863, 0.45285287499427795, 0.4414411187171936, 0.4236391484737396, 0.4642864465713501, 0.4940302073955536, 0.19737736880779266, 0.2957302927970886, 0.2002868354320526, 0.2448350191116333, 0.2718104124069214, 0.2141740322113037, 0.20792452991008759, 0.18669065833091736, 0.2340320646762848, 0.22838930785655975, 0.30520889163017273, 0.2120901644229889, 0.43261319398880005, 0.4434412121772766, 0.3932203948497772, 0.3832606375217438, 0.34323734045028687, 0.39937257766723633, 0.39140328764915466, 0.480873703956604, 0.5836602449417114, 0.5510565042495728, 0.6133751273155212, 0.6937419772148132, 0.5207476615905762, 0.6120167970657349, 0.5470995903015137, 0.5867589712142944, 0.5591728687286377, 0.5882083177566528, 0.6690977811813354, 0.6707751750946045, 0.5575623512268066, 0.6558005213737488, 0.6617739796638489, 0.2308703064918518, 0.18017761409282684, 0.20229974389076233, 0.3056812882423401, 0.1762218475341797, 0.14263096451759338, 0.39197418093681335, 0.24519288539886475, 0.19996795058250427, 0.33275026082992554, 0.4091240465641022, 0.3197367191314697, 0.2854994535446167, 0.21700885891914368, 0.25855642557144165, 0.42575228214263916, 0.3460918664932251, 0.23407918214797974, 0.2143373340368271, 0.41539597511291504, 0.19525694847106934, 0.26718834042549133, 0.22920018434524536, 0.2332262098789215, 0.24392098188400269, 0.26619258522987366, 0.22585293650627136, 0.14866915345191956, 0.15486323833465576, 0.13054443895816803, 0.23543739318847656, 0.1188468486070633, 0.19608470797538757, 0.12236519902944565, 0.2795219421386719, 0.19941049814224243, 0.16270741820335388, 0.14727990329265594, 0.1504337340593338, 0.13587138056755066, 0.16040126979351044, 0.168387770652771, 0.17695783078670502, 0.1824539452791214, 0.5386173725128174, 0.44760191440582275, 0.1338566243648529, 0.22880041599273682, 0.16907358169555664, 0.13281488418579102, 0.11152272671461105, 0.26160356402397156, 0.21330824494361877, 0.27814924716949463, 0.14523549377918243, 0.2228580117225647, 0.12348998337984085, 0.10785560309886932, 0.16938899457454681, 0.09809166193008423, 0.14590269327163696, 0.09470973908901215, 0.21445880830287933, 0.14885590970516205, 0.12407819926738739, 0.11547978222370148, 0.143490269780159, 0.11605395376682281, 0.1269569844007492, 0.12742522358894348, 0.13655902445316315, 0.14285318553447723, 0.4558022618293762, 0.3531830906867981, 0.16846011579036713, 0.13571049273014069, 0.19867044687271118, 0.11707630753517151, 0.13770131766796112, 0.15913432836532593]\n"
     ]
    }
   ],
   "source": [
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deviation greater than threshold : (0.86, 0.40434226393699646)\n",
      "\n",
      "Deviation greater than threshold : (0.86, 0.3860608637332916)\n",
      "\n",
      "Deviation greater than threshold : (0.7, 0.2037433534860611)\n",
      "\n",
      "Deviation greater than threshold : (0.43, 0.11726918071508408)\n",
      "\n",
      "Deviation greater than threshold : (0.67, 0.26017630100250244)\n",
      "\n",
      "Deviation greater than threshold : (0.51, 0.17748603224754333)\n",
      "\n",
      "Deviation greater than threshold : (0.56, 0.22913812100887299)\n",
      "\n",
      "Deviation greater than threshold : (0.68, 0.18800245225429535)\n",
      "\n",
      "Deviation greater than threshold : (0.66, 0.27682578563690186)\n",
      "\n",
      "Deviation greater than threshold : (0.68, 0.37486669421195984)\n",
      "\n",
      "Deviation greater than threshold : (0.74, 0.33969539403915405)\n",
      "\n",
      "Deviation greater than threshold : (1.0, 0.39411965012550354)\n",
      "\n",
      "Deviation greater than threshold : (0.75, 0.3112550973892212)\n",
      "\n",
      "Deviation greater than threshold : (1.0, 0.4491212069988251)\n",
      "\n",
      "Deviation greater than threshold : (0.79, 0.3574565649032593)\n",
      "\n",
      "Deviation greater than threshold : (0.99, 0.29779085516929626)\n",
      "\n",
      "Deviation greater than threshold : (1.0, 0.695366621017456)\n",
      "\n",
      "Deviation greater than threshold : (1.0, 0.6198737621307373)\n",
      "\n",
      "Deviation greater than threshold : (1.0, 0.3044685423374176)\n",
      "\n",
      "Deviation greater than threshold : (0.68, 0.3530732989311218)\n",
      "\n",
      "Deviation greater than threshold : (1.0, 0.3413360118865967)\n",
      "\n",
      "Deviation greater than threshold : (0.47, 0.15988513827323914)\n",
      "\n",
      "Deviation greater than threshold : (0.6, 0.2928209900856018)\n",
      "\n",
      "Deviation greater than threshold : (1.0, 0.3787393569946289)\n",
      "\n",
      "Deviation greater than threshold : (0.91, 0.31121984124183655)\n",
      "\n",
      "Deviation greater than threshold : (0.87, 0.2887954115867615)\n",
      "\n",
      "Deviation greater than threshold : (0.64, 0.17655758559703827)\n",
      "\n",
      "Deviation greater than threshold : (0.7, 0.26998403668403625)\n",
      "\n",
      "Deviation greater than threshold : (0.74, 0.32578983902931213)\n",
      "\n",
      "Deviation greater than threshold : (0.72, 0.38389527797698975)\n",
      "\n",
      "Deviation greater than threshold : (0.71, 0.3230891227722168)\n",
      "\n",
      "Deviation greater than threshold : (0.78, 0.3034341335296631)\n",
      "\n",
      "Deviation greater than threshold : (1.0, 0.42942506074905396)\n",
      "\n",
      "Deviation greater than threshold : (1.0, 0.4414411187171936)\n",
      "\n",
      "Deviation greater than threshold : (0.73, 0.2120901644229889)\n",
      "\n",
      "Deviation greater than threshold : (1.0, 0.480873703956604)\n",
      "\n",
      "Deviation greater than threshold : (1.0, 0.5510565042495728)\n",
      "\n",
      "Deviation greater than threshold : (1.0, 0.5591728687286377)\n",
      "\n",
      "Deviation greater than threshold : (1.0, 0.6690977811813354)\n",
      "\n",
      "Deviation greater than threshold : (1.0, 0.6707751750946045)\n",
      "\n",
      "Deviation greater than threshold : (1.0, 0.5575623512268066)\n",
      "\n",
      "Deviation greater than threshold : (1.0, 0.6617739796638489)\n",
      "\n",
      "Deviation greater than threshold : (0.5, 0.1762218475341797)\n",
      "\n",
      "Deviation greater than threshold : (0.72, 0.39197418093681335)\n",
      "\n",
      "Deviation greater than threshold : (0.58, 0.24519288539886475)\n",
      "\n",
      "Deviation greater than threshold : (1.0, 0.3197367191314697)\n",
      "\n",
      "Deviation greater than threshold : (0.8, 0.41539597511291504)\n",
      "\n",
      "Deviation greater than threshold : (0.57, 0.22585293650627136)\n",
      "\n",
      "Deviation greater than threshold : (1.0, 0.2228580117225647)\n",
      "\n",
      "Deviation greater than threshold : (0.7, 0.3531830906867981)\n",
      "\n",
      "Deviation greater than threshold : (0.5, 0.13571049273014069)\n",
      "\n",
      "The total count where Deviation greater than threshold: 51 of 417\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "for i in positive_samples[['positive_score', 'preds']].itertuples():\n",
    "    if i[1]-i[2] >= 0.3:\n",
    "        print(f\"Deviation greater than threshold : {i[1], i[2]}\\n\")\n",
    "        count+=1\n",
    "\n",
    "print(f\"The total count where Deviation greater than threshold: {count} of {positive_samples.shape[0]}\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d437c2bd0d26a9909614bcc5b04828d6277ae5f269770a7161a0a726ff076161"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 ('myenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
